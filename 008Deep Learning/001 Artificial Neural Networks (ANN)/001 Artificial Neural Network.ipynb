{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
      "0          1    15634602  Hargrave          619    France  Female   42   \n",
      "1          2    15647311      Hill          608     Spain  Female   41   \n",
      "2          3    15619304      Onio          502    France  Female   42   \n",
      "3          4    15701354      Boni          699    France  Female   39   \n",
      "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
      "5          6    15574012       Chu          645     Spain    Male   44   \n",
      "6          7    15592531  Bartlett          822    France    Male   50   \n",
      "7          8    15656148    Obinna          376   Germany  Female   29   \n",
      "8          9    15792365        He          501    France    Male   44   \n",
      "9         10    15592389        H?          684    France    Male   27   \n",
      "\n",
      "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0       2       0.00              1          1               1   \n",
      "1       1   83807.86              1          0               1   \n",
      "2       8  159660.80              3          1               0   \n",
      "3       1       0.00              2          0               0   \n",
      "4       2  125510.82              1          1               1   \n",
      "5       8  113755.78              2          1               0   \n",
      "6       7       0.00              2          1               1   \n",
      "7       4  115046.74              4          1               0   \n",
      "8       4  142051.07              2          0               1   \n",
      "9       2  134603.88              1          1               1   \n",
      "\n",
      "   EstimatedSalary  Exited  \n",
      "0        101348.88       1  \n",
      "1        112542.58       0  \n",
      "2        113931.57       1  \n",
      "3         93826.63       0  \n",
      "4         79084.10       0  \n",
      "5        149756.71       1  \n",
      "6         10062.80       0  \n",
      "7        119346.88       1  \n",
      "8         74940.50       0  \n",
      "9         71725.73       0  \n",
      "         RowNumber    CustomerId   CreditScore           Age        Tenure  \\\n",
      "count  10000.00000  1.000000e+04  10000.000000  10000.000000  10000.000000   \n",
      "mean    5000.50000  1.569094e+07    650.528800     38.921800      5.012800   \n",
      "std     2886.89568  7.193619e+04     96.653299     10.487806      2.892174   \n",
      "min        1.00000  1.556570e+07    350.000000     18.000000      0.000000   \n",
      "25%     2500.75000  1.562853e+07    584.000000     32.000000      3.000000   \n",
      "50%     5000.50000  1.569074e+07    652.000000     37.000000      5.000000   \n",
      "75%     7500.25000  1.575323e+07    718.000000     44.000000      7.000000   \n",
      "max    10000.00000  1.581569e+07    850.000000     92.000000     10.000000   \n",
      "\n",
      "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
      "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
      "mean    76485.889288       1.530200      0.70550        0.515100   \n",
      "std     62397.405202       0.581654      0.45584        0.499797   \n",
      "min         0.000000       1.000000      0.00000        0.000000   \n",
      "25%         0.000000       1.000000      0.00000        0.000000   \n",
      "50%     97198.540000       1.000000      1.00000        1.000000   \n",
      "75%    127644.240000       2.000000      1.00000        1.000000   \n",
      "max    250898.090000       4.000000      1.00000        1.000000   \n",
      "\n",
      "       EstimatedSalary        Exited  \n",
      "count     10000.000000  10000.000000  \n",
      "mean     100090.239881      0.203700  \n",
      "std       57510.492818      0.402769  \n",
      "min          11.580000      0.000000  \n",
      "25%       51002.110000      0.000000  \n",
      "50%      100193.915000      0.000000  \n",
      "75%      149388.247500      0.000000  \n",
      "max      199992.480000      1.000000  \n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "print(dataset.head(10))\n",
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into Independent and Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----X----\n",
      "[[619 'France' 'Female' 42 2 0.0 1 1 1 101348.88]\n",
      " [608 'Spain' 'Female' 41 1 83807.86 1 0 1 112542.58]\n",
      " [502 'France' 'Female' 42 8 159660.8 3 1 0 113931.57]\n",
      " [699 'France' 'Female' 39 1 0.0 2 0 0 93826.63]\n",
      " [850 'Spain' 'Female' 43 2 125510.82 1 1 1 79084.1]\n",
      " [645 'Spain' 'Male' 44 8 113755.78 2 1 0 149756.71]\n",
      " [822 'France' 'Male' 50 7 0.0 2 1 1 10062.8]\n",
      " [376 'Germany' 'Female' 29 4 115046.74 4 1 0 119346.88]\n",
      " [501 'France' 'Male' 44 4 142051.07 2 0 1 74940.5]\n",
      " [684 'France' 'Male' 27 2 134603.88 1 1 1 71725.73]]\n",
      "<class 'numpy.ndarray'>\n",
      "(10000, 10)\n",
      "-----y----\n",
      "[1 0 1 0 0 1 0 1 0 0]\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, 13].values\n",
    "\n",
    "print(\"-----X----\")\n",
    "print(X[:10])\n",
    "print(type(X))\n",
    "print(X.shape)\n",
    "print(\"-----y----\")\n",
    "print(y[:10])\n",
    "print(y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding categorical  data(Geography & Gender into number type data )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make dummy variables for Geography only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[619 'France' 'Female' 42 2 0.0 1 1 1 101348.88]\n",
      "[1.0 0.0 0.0 619 'Female' 42 2 0.0 1 1 1 101348.88]\n"
     ]
    }
   ],
   "source": [
    "print(X[0])\n",
    "from sklearn.compose import ColumnTransformer\n",
    "ct = ColumnTransformer([(\"Geography\", OneHotEncoder(), [1])], remainder = 'passthrough')\n",
    "X = ct.fit_transform(X)\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding categorical  data(Gender into number type data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0 0.0 0.0 619 'Female' 42 2 0.0 1 1 1 101348.88]\n",
      "[1.0 0.0 0.0 619 0 42 2 0.0 1 1 1 101348.88]\n"
     ]
    }
   ],
   "source": [
    "print(X[0])\n",
    "labelencoder_x_2=LabelEncoder()\n",
    "X[:,4]=labelencoder_x_2.fit_transform(X[:,4])\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove dummy variables trap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0 0.0 619 0 42 2 0.0 1 1 1 101348.88]\n"
     ]
    }
   ],
   "source": [
    "X = X[:, 1:]\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----X_train-------\n",
      "[[0.0 1.0 667 0 34 5 0.0 2 1 0 163830.64]\n",
      " [1.0 0.0 427 1 42 1 75681.52 1 1 1 57098.0]\n",
      " [0.0 0.0 535 0 29 2 112367.34 1 1 0 185630.76]\n",
      " [0.0 1.0 654 1 40 5 105683.63 1 1 0 173617.09]\n",
      " [0.0 1.0 850 0 57 8 126776.3 2 1 1 132298.49]]\n",
      "<class 'numpy.ndarray'>\n",
      "(8000, 11)\n",
      "---------X_test------\n",
      "[[1.0 0.0 597 0 35 8 131101.04 1 1 1 192852.67]\n",
      " [0.0 0.0 523 0 40 2 102967.41 1 1 0 128702.1]\n",
      " [0.0 1.0 706 0 42 8 95386.82 1 1 1 75732.25]\n",
      " [0.0 0.0 788 1 32 4 112079.58 1 0 0 89368.59]\n",
      " [1.0 0.0 706 1 38 5 163034.82 2 1 1 135662.17]]\n",
      "<class 'numpy.ndarray'>\n",
      "(2000, 11)\n",
      "---------y_train------\n",
      "[0 0 0 0 0]\n",
      "<class 'numpy.ndarray'>\n",
      "(8000,)\n",
      "---------y_test------\n",
      "[0 1 0 0 0]\n",
      "<class 'numpy.ndarray'>\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(\"-----X_train-------\")\n",
    "print(X_train[:5])\n",
    "print(type(X_train))\n",
    "print(X_train.shape)\n",
    "\n",
    "print(\"---------X_test------\")\n",
    "print(X_test[:5])\n",
    "print(type(X_test))\n",
    "print(X_test.shape)\n",
    "\n",
    "print(\"---------y_train------\")\n",
    "print(y_train[:5])\n",
    "print(type(y_train))\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"---------y_test------\")\n",
    "print(y_test[:5])\n",
    "print(type(y_test))\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----X_train-------\n",
      "[[-0.5698444   1.74309049  0.16958176 -1.09168714 -0.46460796  0.00666099\n",
      "  -1.21571749  0.8095029   0.64259497 -1.03227043  1.10643166]\n",
      " [ 1.75486502 -0.57369368 -2.30455945  0.91601335  0.30102557 -1.37744033\n",
      "  -0.00631193 -0.92159124  0.64259497  0.9687384  -0.74866447]\n",
      " [-0.5698444  -0.57369368 -1.19119591 -1.09168714 -0.94312892 -1.031415\n",
      "   0.57993469 -0.92159124  0.64259497 -1.03227043  1.48533467]\n",
      " [-0.5698444   1.74309049  0.03556578  0.91601335  0.10961719  0.00666099\n",
      "   0.47312769 -0.92159124  0.64259497 -1.03227043  1.27652776]\n",
      " [-0.5698444   1.74309049  2.05611444 -1.09168714  1.73658844  1.04473698\n",
      "   0.8101927   0.8095029   0.64259497  0.9687384   0.55837842]]\n",
      "---------X_test------\n",
      "[[ 1.75486502 -0.57369368 -0.55204276 -1.09168714 -0.36890377  1.04473698\n",
      "   0.8793029  -0.92159124  0.64259497  0.9687384   1.61085707]\n",
      " [-0.5698444  -0.57369368 -1.31490297 -1.09168714  0.10961719 -1.031415\n",
      "   0.42972196 -0.92159124  0.64259497 -1.03227043  0.49587037]\n",
      " [-0.5698444   1.74309049  0.57162971 -1.09168714  0.30102557  1.04473698\n",
      "   0.30858264 -0.92159124  0.64259497  0.9687384  -0.42478674]\n",
      " [-0.5698444  -0.57369368  1.41696129  0.91601335 -0.65601634 -0.33936434\n",
      "   0.57533623 -0.92159124 -1.55619021 -1.03227043 -0.18777657]\n",
      " [ 1.75486502 -0.57369368  0.57162971  0.91601335 -0.08179119  0.00666099\n",
      "   1.38961097  0.8095029   0.64259497  0.9687384   0.61684179]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "print(\"-----X_train-------\")\n",
    "print(X_train[:5])\n",
    "print(\"---------X_test------\")\n",
    "print(X_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Now let's make the ANN!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Keras libraries and packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Using TensorFlow backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The sequential module that is required to initialize our neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the dense module that is required to build the layers of our in\n",
    "## Randomly initialise the weight to small numbers close to zero( but not zero '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialising the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the input layer and the first hidden layer\n",
    "## add() : Method to add layer in ANN\n",
    "## Dense() : Randomly initialise the weight to small numbers close to zero( but not zero '0')\n",
    "## output_dim [ (no of i/p var + no of o/p var)/2][(11+1)/2=6] output_dim = 6\n",
    "## kernel_initializer = 'uniform' : Randomly initialise the weight  \n",
    "## activation = 'relu'-> rectifier for hidden layer  activation function \n",
    "## No of independent var :1input_dim = 11\n",
    "\n",
    "classifier.add(Dense(output_dim = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the second hidden layer [the second hidden layer Well it knows what to expect because the first hidden layer was created.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(kernel_initializer=\"uniform\", activation=\"relu\", units=6)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim = 6, kernel_initializer = 'uniform', activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the output layer\n",
    "## output_dim = 1 beacause we have only one output.\n",
    "## activation = 'sigmoid'-> sigmoid for hidden layer  activation function [sigmoid heart of probability aproch]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(kernel_initializer=\"uniform\", activation=\"sigmoid\", units=1)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  dependent variable that has more than two categories like say for example three categories: output parameter ana activation = 'Soft_max'\n",
    "\n",
    "##  Compiling the ANN [applying stochastic on the whole artificial neural network.]\n",
    "## compile()  method \n",
    "\"\"\"optimizer = Adam' is the algorithm you want to use to find the optimal set of weights in the neural networks \n",
    "because you know we defined our neural networks it is built with the different layers but the weights are still only initialized.\n",
    "several types of stochastic and descent algorithm and a very efficient one is called 'Adam'\n",
    "loss = 'binary_crossentropy' : Stochastic is based on a lost function that you need to optimize to find the optimal weights. \n",
    "metrics = ['accuracy'] : metrics accuracy criterion algorithm for weight adjust to improve the models performance\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Fitting the ANN to the Training set\n",
    "##  use the fit method that will fit our ANN into the training sets.\n",
    "##  nb_epoch = 100 : epoch is number of times whole training set passed through the ANN\n",
    "##  epoch is number of times whole training set passed through the ANN \n",
    "##  [Algo Of Training the ANN with Stochastic Descent: applying steps 1 to 6 over many epochs.]\n",
    "##  batch_size = 10 : \n",
    "##  Update weight after each observations [ Reinforcement Learning] \n",
    "##  or Update weight after batch of observations [Batch Learning]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 3s 390us/step - loss: 0.4999 - accuracy: 0.7949\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 1s 123us/step - loss: 0.4278 - accuracy: 0.7960\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 1s 127us/step - loss: 0.4235 - accuracy: 0.7960\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 124us/step - loss: 0.4207 - accuracy: 0.7961\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 118us/step - loss: 0.4181 - accuracy: 0.8209\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 1s 123us/step - loss: 0.4159 - accuracy: 0.8284\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 130us/step - loss: 0.4141 - accuracy: 0.8288\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 117us/step - loss: 0.4127 - accuracy: 0.8296\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s 118us/step - loss: 0.4112 - accuracy: 0.8330\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 118us/step - loss: 0.4102 - accuracy: 0.8334\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 1s 117us/step - loss: 0.4092 - accuracy: 0.8332\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 1s 118us/step - loss: 0.4083 - accuracy: 0.8320\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 1s 119us/step - loss: 0.4075 - accuracy: 0.83380s -\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 1s 117us/step - loss: 0.4070 - accuracy: 0.8320\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 1s 123us/step - loss: 0.4063 - accuracy: 0.8342\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 1s 118us/step - loss: 0.4057 - accuracy: 0.8351\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 1s 121us/step - loss: 0.4055 - accuracy: 0.8339\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 1s 119us/step - loss: 0.4050 - accuracy: 0.8336\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 1s 120us/step - loss: 0.4049 - accuracy: 0.8347\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 1s 127us/step - loss: 0.4047 - accuracy: 0.8360\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 1s 120us/step - loss: 0.4039 - accuracy: 0.8344\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 1s 119us/step - loss: 0.4040 - accuracy: 0.8342\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 1s 123us/step - loss: 0.4036 - accuracy: 0.8359\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 1s 133us/step - loss: 0.4032 - accuracy: 0.8353\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 1s 117us/step - loss: 0.4030 - accuracy: 0.8356\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 1s 118us/step - loss: 0.4029 - accuracy: 0.8359\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 1s 117us/step - loss: 0.4028 - accuracy: 0.8341\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 1s 120us/step - loss: 0.4024 - accuracy: 0.8357\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 1s 145us/step - loss: 0.4027 - accuracy: 0.8354\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 1s 160us/step - loss: 0.4023 - accuracy: 0.8357\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 1s 144us/step - loss: 0.4022 - accuracy: 0.8342\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 1s 147us/step - loss: 0.4021 - accuracy: 0.8357\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 1s 123us/step - loss: 0.4021 - accuracy: 0.8353\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 1s 142us/step - loss: 0.4017 - accuracy: 0.8351\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 1s 128us/step - loss: 0.4016 - accuracy: 0.8347\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 1s 150us/step - loss: 0.4017 - accuracy: 0.8351\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 1s 139us/step - loss: 0.4015 - accuracy: 0.8355\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 1s 123us/step - loss: 0.4014 - accuracy: 0.8357\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 1s 113us/step - loss: 0.4012 - accuracy: 0.8350\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 1s 115us/step - loss: 0.4010 - accuracy: 0.8342\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 1s 118us/step - loss: 0.4014 - accuracy: 0.8353\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.4002 - accuracy: 0.83 - 1s 125us/step - loss: 0.4011 - accuracy: 0.8354\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.4010 - accuracy: 0.8357\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.4010 - accuracy: 0.8356\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 1s 118us/step - loss: 0.4012 - accuracy: 0.8349\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 1s 122us/step - loss: 0.4009 - accuracy: 0.8359\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.4010 - accuracy: 0.8341\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 1s 117us/step - loss: 0.4010 - accuracy: 0.8353\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 1s 118us/step - loss: 0.4009 - accuracy: 0.8354\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 1s 115us/step - loss: 0.4007 - accuracy: 0.8355\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.4005 - accuracy: 0.8364\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 1s 113us/step - loss: 0.4005 - accuracy: 0.8341\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 1s 112us/step - loss: 0.4010 - accuracy: 0.8349\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 1s 121us/step - loss: 0.4005 - accuracy: 0.8354\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 1s 133us/step - loss: 0.4006 - accuracy: 0.8351\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 1s 127us/step - loss: 0.4002 - accuracy: 0.8353\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 1s 121us/step - loss: 0.4007 - accuracy: 0.8361\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 1s 124us/step - loss: 0.4005 - accuracy: 0.8349\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 1s 129us/step - loss: 0.4004 - accuracy: 0.8355\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 1s 122us/step - loss: 0.4003 - accuracy: 0.8360\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 1s 119us/step - loss: 0.4002 - accuracy: 0.8347\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 1s 121us/step - loss: 0.4002 - accuracy: 0.8353\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 1s 120us/step - loss: 0.4004 - accuracy: 0.8354\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 1s 112us/step - loss: 0.4003 - accuracy: 0.8359\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 1s 128us/step - loss: 0.4005 - accuracy: 0.8345\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 1s 112us/step - loss: 0.4000 - accuracy: 0.8334\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 1s 132us/step - loss: 0.4000 - accuracy: 0.8353\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 1s 118us/step - loss: 0.4005 - accuracy: 0.8355\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 1s 112us/step - loss: 0.4001 - accuracy: 0.8349\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 1s 112us/step - loss: 0.4004 - accuracy: 0.8350\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.3999 - accuracy: 0.8357\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 1s 113us/step - loss: 0.4003 - accuracy: 0.8349\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 1s 113us/step - loss: 0.3996 - accuracy: 0.8357\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 1s 122us/step - loss: 0.4001 - accuracy: 0.8344\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 1s 114us/step - loss: 0.4001 - accuracy: 0.8351\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 1s 123us/step - loss: 0.4002 - accuracy: 0.8346\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 1s 115us/step - loss: 0.4001 - accuracy: 0.8356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 1s 113us/step - loss: 0.3999 - accuracy: 0.8350\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 1s 108us/step - loss: 0.4001 - accuracy: 0.8364\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 1s 106us/step - loss: 0.4000 - accuracy: 0.8371\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 1s 106us/step - loss: 0.4001 - accuracy: 0.8364\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 1s 107us/step - loss: 0.4001 - accuracy: 0.8350\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 1s 107us/step - loss: 0.4002 - accuracy: 0.8357\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 1s 109us/step - loss: 0.4000 - accuracy: 0.8361\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 1s 109us/step - loss: 0.3998 - accuracy: 0.8365\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 1s 106us/step - loss: 0.3999 - accuracy: 0.8356\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 1s 107us/step - loss: 0.3999 - accuracy: 0.8353\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 1s 117us/step - loss: 0.3997 - accuracy: 0.8354\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 1s 134us/step - loss: 0.3995 - accuracy: 0.8364\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 1s 108us/step - loss: 0.4000 - accuracy: 0.8359\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 1s 107us/step - loss: 0.3997 - accuracy: 0.8374\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.3997 - accuracy: 0.8360\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 1s 112us/step - loss: 0.3998 - accuracy: 0.8332\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 1s 114us/step - loss: 0.3997 - accuracy: 0.8353\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.3998 - accuracy: 0.8360\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.3997 - accuracy: 0.8354\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 1s 118us/step - loss: 0.3995 - accuracy: 0.8351\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 1s 136us/step - loss: 0.3997 - accuracy: 0.8364\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 1s 120us/step - loss: 0.3994 - accuracy: 0.8357\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 1s 123us/step - loss: 0.3995 - accuracy: 0.8350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1dff1771c08>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "classifier.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Making the predictions and evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False]\n",
      " [False]\n",
      " [False]\n",
      " ...\n",
      " [False]\n",
      " [False]\n",
      " [False]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Making the Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1557   38]\n",
      " [ 282  123]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
